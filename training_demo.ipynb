{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.8 64-bit ('venv')",
   "display_name": "Python 3.6.8 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "db31494cdddb3bd1604847e5831987a1545b230cef5defdb7d44cb0d53a71f7c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['http_proxy'] = 'http://127.0.0.1:12639'\n",
    "# os.environ['https_proxy'] = 'http://127.0.0.1:12639'\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class SimpleCNN(pl.LightningModule):\n",
    "    def __init__(self, num_classes=2, num_channels=1, target_sr=16000, conv_targ_out_size=2000):\n",
    "        super().__init__()\n",
    "        # init a pretrained resnet\n",
    "        self.num_classes = num_classes\n",
    "        self.conv_targ_out_size = conv_targ_out_size\n",
    "        # self.conv1 = nn.Conv1d(num_channels, 2, 5)\n",
    "        # self.conv2 = nn.Conv1d(2, 4, 5)\n",
    "        # self.pool = nn.MaxPool1d(2)\n",
    "        # self.adaptive_pool = nn.AdaptiveMaxPool1d(conv_targ_out_size)\n",
    "        self.conv1 = nn.Conv2d(num_channels, 2, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(2, 4, 5)\n",
    "        self.adaptive_pool = nn.AdaptiveMaxPool2d((40, 50))\n",
    "        self.fc1 = nn.Linear(4 * conv_targ_out_size, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print('==========')\n",
    "        print(x.shape)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        print(x.shape)\n",
    "        x = self.adaptive_pool(F.relu(self.conv2(x)))\n",
    "        print(x.shape)\n",
    "        x = x.view(-1, 4 * self.conv_targ_out_size)\n",
    "        print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        print(x.shape)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, target = batch\n",
    "        preds = self.forward(images)\n",
    "        loss = F.cross_entropy(preds, target)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "source": [
    "Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def wav_loader(fn, num_channels=1, target_sr=44100):\n",
    "#     waveform, sr = torchaudio.load(fn)\n",
    "#     transformed = torchaudio.transforms.Resample(sr, target_sr)(waveform[:num_channels,:])\n",
    "#     return transformed\n",
    "\n",
    "from audio_classifier.wav2vec.wav2vec import Wav2VecFeat\n",
    "\n",
    "wav2vec_feat = Wav2VecFeat()\n",
    "\n",
    "def wav_loader(fn, num_channels=1, target_sr=16000):\n",
    "    waveform, sr = torchaudio.load(fn)\n",
    "    transformed = torchaudio.transforms.Resample(sr, target_sr)(waveform[:num_channels,:])\n",
    "    features = wav2vec_feat.extract_feature(transformed)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(dataset, batch_size=1):\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle = True\n",
    "    )\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = create_dataloader(datasets.DatasetFolder('demo_data', loader=wav_loader, extensions='.wav'))"
   ]
  },
  {
   "source": [
    "Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\n\n  | Name          | Type              | Params\n----------------------------------------------------\n0 | conv1         | Conv2d            | 52    \n1 | pool          | MaxPool2d         | 0     \n2 | conv2         | Conv2d            | 204   \n3 | adaptive_pool | AdaptiveMaxPool2d | 0     \n4 | fc1           | Linear            | 960 K \n5 | fc2           | Linear            | 10 K  \n6 | fc3           | Linear            | 170   \nEpoch 0:   0%|          | 0/60 [00:00&lt;?, ?it/s] ==========\ntorch.Size([1, 1, 512, 1551])\ntorch.Size([1, 2, 254, 773])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:   2%|▏         | 1/60 [00:04&lt;04:02,  4.11s/it, loss=0.683, v_num=14]==========\ntorch.Size([1, 1, 512, 950])\ntorch.Size([1, 2, 254, 473])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:   3%|▎         | 2/60 [00:06&lt;02:54,  3.01s/it, loss=0.587, v_num=14]==========\ntorch.Size([1, 1, 512, 950])\ntorch.Size([1, 2, 254, 473])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:   5%|▌         | 3/60 [00:08&lt;02:35,  2.73s/it, loss=0.489, v_num=14]==========\ntorch.Size([1, 1, 512, 1349])\ntorch.Size([1, 2, 254, 672])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:   7%|▋         | 4/60 [00:11&lt;02:37,  2.80s/it, loss=0.896, v_num=14]==========\ntorch.Size([1, 1, 512, 1152])\ntorch.Size([1, 2, 254, 574])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:   8%|▊         | 5/60 [00:13&lt;02:26,  2.66s/it, loss=1.099, v_num=14]==========\ntorch.Size([1, 1, 512, 950])\ntorch.Size([1, 2, 254, 473])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  10%|█         | 6/60 [00:15&lt;02:21,  2.61s/it, loss=0.953, v_num=14]==========\ntorch.Size([1, 1, 512, 1349])\ntorch.Size([1, 2, 254, 672])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  12%|█▏        | 7/60 [00:19&lt;02:24,  2.74s/it, loss=0.857, v_num=14]==========\ntorch.Size([1, 1, 512, 1551])\ntorch.Size([1, 2, 254, 773])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  13%|█▎        | 8/60 [00:23&lt;02:32,  2.94s/it, loss=0.790, v_num=14]==========\ntorch.Size([1, 1, 512, 1349])\ntorch.Size([1, 2, 254, 672])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  15%|█▌        | 9/60 [00:26&lt;02:32,  2.99s/it, loss=0.737, v_num=14]==========\ntorch.Size([1, 1, 512, 1251])\ntorch.Size([1, 2, 254, 623])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  17%|█▋        | 10/60 [00:29&lt;02:29,  2.98s/it, loss=0.691, v_num=14]==========\ntorch.Size([1, 1, 512, 1451])\ntorch.Size([1, 2, 254, 723])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  18%|█▊        | 11/60 [00:32&lt;02:26,  2.99s/it, loss=0.649, v_num=14]==========\ntorch.Size([1, 1, 512, 1251])\ntorch.Size([1, 2, 254, 623])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  20%|██        | 12/60 [00:35&lt;02:23,  2.98s/it, loss=0.731, v_num=14]==========\ntorch.Size([1, 1, 512, 1251])\ntorch.Size([1, 2, 254, 623])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  22%|██▏       | 13/60 [00:38&lt;02:19,  2.98s/it, loss=0.794, v_num=14]==========\ntorch.Size([1, 1, 512, 1251])\ntorch.Size([1, 2, 254, 623])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  23%|██▎       | 14/60 [00:41&lt;02:16,  2.96s/it, loss=0.844, v_num=14]==========\ntorch.Size([1, 1, 512, 1049])\ntorch.Size([1, 2, 254, 522])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  25%|██▌       | 15/60 [00:44&lt;02:13,  2.96s/it, loss=0.810, v_num=14]==========\ntorch.Size([1, 1, 512, 1451])\ntorch.Size([1, 2, 254, 723])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  27%|██▋       | 16/60 [00:47&lt;02:10,  2.98s/it, loss=0.784, v_num=14]==========\ntorch.Size([1, 1, 512, 1049])\ntorch.Size([1, 2, 254, 522])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  28%|██▊       | 17/60 [00:50&lt;02:06,  2.94s/it, loss=0.763, v_num=14]==========\ntorch.Size([1, 1, 512, 1349])\ntorch.Size([1, 2, 254, 672])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  30%|███       | 18/60 [00:53&lt;02:04,  2.96s/it, loss=0.775, v_num=14]==========\ntorch.Size([1, 1, 512, 1152])\ntorch.Size([1, 2, 254, 574])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  32%|███▏      | 19/60 [00:55&lt;02:00,  2.94s/it, loss=0.782, v_num=14]==========\ntorch.Size([1, 1, 512, 1251])\ntorch.Size([1, 2, 254, 623])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  33%|███▎      | 20/60 [00:59&lt;01:58,  2.95s/it, loss=0.771, v_num=14]==========\ntorch.Size([1, 1, 512, 1651])\ntorch.Size([1, 2, 254, 823])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  35%|███▌      | 21/60 [01:02&lt;01:56,  3.00s/it, loss=0.778, v_num=14]==========\ntorch.Size([1, 1, 512, 1152])\ntorch.Size([1, 2, 254, 574])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  37%|███▋      | 22/60 [01:05&lt;01:53,  2.98s/it, loss=0.793, v_num=14]==========\ntorch.Size([1, 1, 512, 950])\ntorch.Size([1, 2, 254, 473])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  38%|███▊      | 23/60 [01:07&lt;01:49,  2.95s/it, loss=0.815, v_num=14]==========\ntorch.Size([1, 1, 512, 1349])\ntorch.Size([1, 2, 254, 672])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  40%|████      | 24/60 [01:10&lt;01:46,  2.95s/it, loss=0.744, v_num=14]==========\ntorch.Size([1, 1, 512, 950])\ntorch.Size([1, 2, 254, 473])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  42%|████▏     | 25/60 [01:12&lt;01:41,  2.91s/it, loss=0.682, v_num=14]==========\ntorch.Size([1, 1, 512, 1049])\ntorch.Size([1, 2, 254, 522])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  43%|████▎     | 26/60 [01:15&lt;01:38,  2.90s/it, loss=0.708, v_num=14]==========\ntorch.Size([1, 1, 512, 1451])\ntorch.Size([1, 2, 254, 723])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  45%|████▌     | 27/60 [01:18&lt;01:36,  2.92s/it, loss=0.730, v_num=14]==========\ntorch.Size([1, 1, 512, 1451])\ntorch.Size([1, 2, 254, 723])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  47%|████▋     | 28/60 [01:22&lt;01:34,  2.96s/it, loss=0.748, v_num=14]==========\ntorch.Size([1, 1, 512, 1451])\ntorch.Size([1, 2, 254, 723])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  48%|████▊     | 29/60 [01:26&lt;01:32,  2.97s/it, loss=0.768, v_num=14]==========\ntorch.Size([1, 1, 512, 950])\ntorch.Size([1, 2, 254, 473])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  50%|█████     | 30/60 [01:28&lt;01:28,  2.95s/it, loss=0.789, v_num=14]==========\ntorch.Size([1, 1, 512, 1349])\ntorch.Size([1, 2, 254, 672])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  52%|█████▏    | 31/60 [01:31&lt;01:25,  2.95s/it, loss=0.812, v_num=14]==========\ntorch.Size([1, 1, 512, 1049])\ntorch.Size([1, 2, 254, 522])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  53%|█████▎    | 32/60 [01:33&lt;01:22,  2.93s/it, loss=0.766, v_num=14]==========\ntorch.Size([1, 1, 512, 1152])\ntorch.Size([1, 2, 254, 574])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  55%|█████▌    | 33/60 [01:36&lt;01:19,  2.93s/it, loss=0.722, v_num=14]==========\ntorch.Size([1, 1, 512, 1349])\ntorch.Size([1, 2, 254, 672])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  57%|█████▋    | 34/60 [01:39&lt;01:16,  2.94s/it, loss=0.684, v_num=14]==========\ntorch.Size([1, 1, 512, 1152])\ntorch.Size([1, 2, 254, 574])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  58%|█████▊    | 35/60 [01:42&lt;01:13,  2.93s/it, loss=0.701, v_num=14]==========\ntorch.Size([1, 1, 512, 1152])\ntorch.Size([1, 2, 254, 574])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  60%|██████    | 36/60 [01:45&lt;01:10,  2.94s/it, loss=0.714, v_num=14]==========\ntorch.Size([1, 1, 512, 1748])\ntorch.Size([1, 2, 254, 872])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  62%|██████▏   | 37/60 [01:50&lt;01:08,  2.99s/it, loss=0.723, v_num=14]==========\ntorch.Size([1, 1, 512, 1152])\ntorch.Size([1, 2, 254, 574])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  63%|██████▎   | 38/60 [01:53&lt;01:05,  2.98s/it, loss=0.716, v_num=14]==========\ntorch.Size([1, 1, 512, 1251])\ntorch.Size([1, 2, 254, 623])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  65%|██████▌   | 39/60 [01:55&lt;01:02,  2.97s/it, loss=0.698, v_num=14]==========\ntorch.Size([1, 1, 512, 1251])\ntorch.Size([1, 2, 254, 623])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  67%|██████▋   | 40/60 [01:59&lt;00:59,  2.98s/it, loss=0.714, v_num=14]==========\ntorch.Size([1, 1, 512, 1551])\ntorch.Size([1, 2, 254, 773])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  68%|██████▊   | 41/60 [02:04&lt;00:57,  3.03s/it, loss=0.699, v_num=14]==========\ntorch.Size([1, 1, 512, 1851])\ntorch.Size([1, 2, 254, 923])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  70%|███████   | 42/60 [02:09&lt;00:55,  3.08s/it, loss=0.685, v_num=14]==========\ntorch.Size([1, 1, 512, 1551])\ntorch.Size([1, 2, 254, 773])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  72%|███████▏  | 43/60 [02:12&lt;00:52,  3.09s/it, loss=0.674, v_num=14]==========\ntorch.Size([1, 1, 512, 1049])\ntorch.Size([1, 2, 254, 522])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  73%|███████▎  | 44/60 [02:15&lt;00:49,  3.09s/it, loss=0.663, v_num=14]==========\ntorch.Size([1, 1, 512, 1851])\ntorch.Size([1, 2, 254, 923])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  75%|███████▌  | 45/60 [02:21&lt;00:47,  3.14s/it, loss=0.680, v_num=14]==========\ntorch.Size([1, 1, 512, 1551])\ntorch.Size([1, 2, 254, 773])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  77%|███████▋  | 46/60 [02:25&lt;00:44,  3.17s/it, loss=0.694, v_num=14]==========\ntorch.Size([1, 1, 512, 1651])\ntorch.Size([1, 2, 254, 823])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  78%|███████▊  | 47/60 [02:30&lt;00:41,  3.20s/it, loss=0.712, v_num=14]==========\ntorch.Size([1, 1, 512, 1349])\ntorch.Size([1, 2, 254, 672])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  80%|████████  | 48/60 [02:34&lt;00:38,  3.22s/it, loss=0.700, v_num=14]==========\ntorch.Size([1, 1, 512, 1748])\ntorch.Size([1, 2, 254, 872])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  82%|████████▏ | 49/60 [02:38&lt;00:35,  3.23s/it, loss=0.689, v_num=14]==========\ntorch.Size([1, 1, 512, 1152])\ntorch.Size([1, 2, 254, 574])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  83%|████████▎ | 50/60 [02:40&lt;00:32,  3.22s/it, loss=0.679, v_num=14]==========\ntorch.Size([1, 1, 512, 1349])\ntorch.Size([1, 2, 254, 672])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  85%|████████▌ | 51/60 [02:43&lt;00:28,  3.21s/it, loss=0.668, v_num=14]==========\ntorch.Size([1, 1, 512, 1049])\ntorch.Size([1, 2, 254, 522])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nEpoch 0:  87%|████████▋ | 52/60 [02:47&lt;00:25,  3.22s/it, loss=0.656, v_num=14]==========\ntorch.Size([1, 1, 512, 2350])\ntorch.Size([1, 2, 254, 1173])\ntorch.Size([1, 4, 40, 50])\ntorch.Size([1, 8000])\ntorch.Size([1, 120])\nSaving latest checkpoint..\nEpoch 0:  87%|████████▋ | 52/60 [02:54&lt;00:26,  3.36s/it, loss=0.656, v_num=14]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1"
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "model = SimpleCNN()\n",
    "trainer = pl.Trainer(max_epochs=5, gpus=torch.cuda.device_count())\n",
    "trainer.fit(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}